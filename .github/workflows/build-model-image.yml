name: Build and Push Model Container to GHCR

on:
  workflow_dispatch:
    inputs:
      model_name:
        description: 'Model name (e.g., zai-org/GLM-4.5-FP8)'
        required: true
        default: 'zai-org/GLM-4.5-FP8'
        type: string
      image_tag:
        description: 'Additional tag for the image (optional)'
        required: false
        type: string
  push:
    branches:
      - main
    paths:
      - 'Dockerfile'
      - '.github/workflows/build-model-image.yml'

env:
  REGISTRY: ghcr.io
  BASE_IMAGE_NAME: ${{ github.repository }}/vllm-model

jobs:
  build-and-push:
    # Use self-hosted runner with specific labels
    runs-on: self-hosted
    # Alternative: Use specific runner labels if you have multiple runners
    # runs-on: [self-hosted, linux, x64, docker]
    
    permissions:
      contents: read
      packages: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to GitHub Container Registry (GHCR)
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Verify GHCR login
        run: |
          echo "‚úÖ Successfully logged into GHCR"
          echo "Registry: ${{ env.REGISTRY }}"
          echo "Username: ${{ github.actor }}"
          echo "Repository: ${{ github.repository }}"

      - name: Set model name and image name
        id: meta
        run: |
          # Use input model name if provided, otherwise default
          MODEL_NAME="${{ inputs.model_name || 'zai-org/GLM-4.5-FP8' }}"
          echo "model_name=${MODEL_NAME}" >> $GITHUB_OUTPUT
          
          # Create sanitized image name from model name
          # Replace / with - and convert to lowercase
          SANITIZED_MODEL=$(echo "${MODEL_NAME}" | tr '/' '-' | tr '[:upper:]' '[:lower:]')
          IMAGE_NAME="${{ env.REGISTRY }}/${{ env.BASE_IMAGE_NAME }}-${SANITIZED_MODEL}"
          echo "image_name=${IMAGE_NAME}" >> $GITHUB_OUTPUT
          echo "sanitized_model=${SANITIZED_MODEL}" >> $GITHUB_OUTPUT
          
          # Set tags
          TAGS="${IMAGE_NAME}:latest,${IMAGE_NAME}:${{ github.sha }}"
          if [ -n "${{ inputs.image_tag }}" ]; then
            TAGS="${TAGS},${IMAGE_NAME}:${{ inputs.image_tag }}"
          fi
          echo "tags=${TAGS}" >> $GITHUB_OUTPUT

      - name: Extract metadata
        id: docker_meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ steps.meta.outputs.image_name }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=sha,prefix={{branch}}-
            type=raw,value=latest,enable={{is_default_branch}}
            type=raw,value=${{ inputs.image_tag }},enable=${{ inputs.image_tag != '' }}

      - name: Build and push Docker image to GHCR
        uses: docker/build-push-action@v5
        id: build
        with:
          context: .
          file: ./Dockerfile
          push: true
          tags: ${{ steps.docker_meta.outputs.tags }}
          labels: ${{ steps.docker_meta.outputs.labels }}
          build-args: |
            MODEL_NAME=${{ steps.meta.outputs.model_name }}
          # Use local cache for self-hosted runners instead of GitHub Actions cache
          cache-from: type=local,src=/tmp/.buildx-cache
          cache-to: type=local,dest=/tmp/.buildx-cache-new,mode=max
          platforms: linux/amd64

      # Cache cleanup for self-hosted runners
      - name: Move cache
        run: |
          rm -rf /tmp/.buildx-cache
          mv /tmp/.buildx-cache-new /tmp/.buildx-cache

      - name: Verify GHCR push and output details
        run: |
          echo "üöÄ Successfully built and pushed container image to GHCR!"
          echo "üì¶ Model: ${{ steps.meta.outputs.model_name }}"
          echo "üè∑Ô∏è  Image: ${{ steps.meta.outputs.image_name }}"
          echo "üîñ Tags pushed to GHCR:"
          echo "${{ steps.docker_meta.outputs.tags }}" | tr ',' '\n' | sed 's/^/  - /'
          echo ""
          echo "üìã Image Digest: ${{ steps.build.outputs.digest }}"
          echo ""
          echo "üê≥ Pull commands:"
          echo "${{ steps.docker_meta.outputs.tags }}" | tr ',' '\n' | sed 's/^/docker pull /'
          echo ""
          echo "üîó View in GHCR: https://github.com/${{ github.repository }}/pkgs/container/vllm-model-${{ steps.meta.outputs.sanitized_model }}"

      - name: Verify image is available in GHCR
        run: |
          echo "üîç Verifying image is available in GHCR..."
          # Get the main image tag (latest)
          IMAGE_URL="${{ steps.meta.outputs.image_name }}:latest"
          echo "Checking: $IMAGE_URL"
          
          # Use docker manifest inspect to verify the image exists
          if docker manifest inspect "$IMAGE_URL" > /dev/null 2>&1; then
            echo "‚úÖ Image successfully pushed and available at: $IMAGE_URL"
          else
            echo "‚ùå Warning: Could not verify image availability (this might be normal delay)"
            echo "   The image should be available shortly at: $IMAGE_URL"
          fi
          
      - name: Create deployment example
        run: |
          cat << EOF > deployment-example.md
          # Deployment Example - GHCR Images
          
          ## Model Information
          - **Model**: ${{ steps.meta.outputs.model_name }}
          - **GHCR Image**: ${{ steps.meta.outputs.image_name }}:latest
          - **Registry**: GitHub Container Registry (ghcr.io)
          
          ## Docker Login to GHCR (if pulling private images)
          \`\`\`bash
          echo "\$GITHUB_TOKEN" | docker login ghcr.io -u \$GITHUB_USERNAME --password-stdin
          \`\`\`
          
          ## Docker Run
          \`\`\`bash
          docker run -d \\
            --name vllm-${{ steps.meta.outputs.sanitized_model }} \\
            -p 8000:8000 \\
            --gpus all \\
            ${{ steps.meta.outputs.image_name }}:latest
          \`\`\`
          
          ## Docker Compose
          \`\`\`yaml
          version: '3.8'
          services:
            vllm-model:
              image: ${{ steps.meta.outputs.image_name }}:latest
              ports:
                - "8000:8000"
              deploy:
                resources:
                  reservations:
                    devices:
                      - driver: nvidia
                        count: all
                        capabilities: [gpu]
              environment:
                - MODEL_NAME=${{ steps.meta.outputs.model_name }}
          \`\`\`
          
          ## Testing the API
          \`\`\`bash
          # Health check
          curl http://localhost:8000/health
          
          # List models
          curl http://localhost:8000/v1/models
          
          # Chat completion
          curl -X POST http://localhost:8000/v1/chat/completions \\
            -H "Content-Type: application/json" \\
            -d '{
              "model": "${{ steps.meta.outputs.model_name }}",
              "messages": [{"role": "user", "content": "Hello!"}],
              "max_tokens": 100
            }'
          \`\`\`
          EOF
          